{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                        MBAN 5110 U - PREDICTIVE MODELLING\n",
    "                                               \n",
    "                                                                               Midterm Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1 (20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use ‚Äúmidterm_partone.csv‚Äù file that contains the stock-return information of small retailers (the same as the one we used in Session 5). Suppose that an industry expert (e.g., David Berman) claims that there is a bias in moment conditions of instrumental variables such that ùëç ! (ùëå ‚àí ùëãùêµ) = ùõø where ùõø has a non-zero value.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We first import the basic libraries to our Jupiter Notebook which will help in our analysis and deciphering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS \n",
    "# There is a package named IV2SLS in Python. Do not use this package! The exogenous explanatory variables must\n",
    "# be entered as instruments. So it gives wrong answers\n",
    "from statsmodels.sandbox.regression.gmm import GMM\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score, classification_report, precision_recall_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the midterm_partone data set from your local file on the computer and store it as 'input_table'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_table = pd.read_csv('/Users/pratiksha/Downloads/midterm_partone.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the below function to display the first few rows of the DataFrame 'input_table', providing a preview of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Constant</th>\n",
       "      <th>Stock Change</th>\n",
       "      <th>Inventory Turnover</th>\n",
       "      <th>Operating Profit</th>\n",
       "      <th>Interaction Effect</th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Quick Ratio</th>\n",
       "      <th>Debt Asset Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.870332</td>\n",
       "      <td>1.795946</td>\n",
       "      <td>0.115846</td>\n",
       "      <td>0.208053</td>\n",
       "      <td>1.672527</td>\n",
       "      <td>0.255171</td>\n",
       "      <td>0.473317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.047347</td>\n",
       "      <td>1.395501</td>\n",
       "      <td>0.436967</td>\n",
       "      <td>0.609788</td>\n",
       "      <td>1.637261</td>\n",
       "      <td>0.221763</td>\n",
       "      <td>0.489967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>1.664563</td>\n",
       "      <td>0.541016</td>\n",
       "      <td>0.900555</td>\n",
       "      <td>1.640619</td>\n",
       "      <td>0.189141</td>\n",
       "      <td>0.374269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.901200</td>\n",
       "      <td>1.605738</td>\n",
       "      <td>0.539399</td>\n",
       "      <td>0.866133</td>\n",
       "      <td>1.436221</td>\n",
       "      <td>0.131944</td>\n",
       "      <td>0.224399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.176353</td>\n",
       "      <td>1.591451</td>\n",
       "      <td>0.539938</td>\n",
       "      <td>0.859285</td>\n",
       "      <td>1.433140</td>\n",
       "      <td>0.183095</td>\n",
       "      <td>0.213446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Constant  Stock Change  Inventory Turnover  Operating Profit   \n",
       "0         1      0.870332            1.795946          0.115846  \\\n",
       "1         1     -0.047347            1.395501          0.436967   \n",
       "2         1      0.001176            1.664563          0.541016   \n",
       "3         1     -0.901200            1.605738          0.539399   \n",
       "4         1     -0.176353            1.591451          0.539938   \n",
       "\n",
       "   Interaction Effect  Current Ratio  Quick Ratio  Debt Asset Ratio  \n",
       "0            0.208053       1.672527     0.255171          0.473317  \n",
       "1            0.609788       1.637261     0.221763          0.489967  \n",
       "2            0.900555       1.640619     0.189141          0.374269  \n",
       "3            0.866133       1.436221     0.131944          0.224399  \n",
       "4            0.859285       1.433140     0.183095          0.213446  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is creating a model that tries to predict the \"Inventory Turnover\" based on other factors like \"Current Ratio,\" \"Quick Ratio,\" and \"Debt Asset Ratio.\" Using this model, it predicts what the \"Inventory Turnover\" values would be for the given input factors. The predicted values are then stored in a new column called \"Endogenous Param\" in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iv = sm.OLS(input_table[\"Inventory Turnover\"],input_table[[\"Constant\",\"Current Ratio\",\"Quick Ratio\",\\\n",
    "                                                                 \"Debt Asset Ratio\"]]).fit()\n",
    "endog_predict = model_iv.predict(input_table[[\"Constant\",\"Current Ratio\",\"Quick Ratio\",\"Debt Asset Ratio\"]])\n",
    "input_table[\"Endogenous Param\"] = endog_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is fitting an Ordinary Least Squares (OLS) regression model using the Statsmodels library. The dependent variable in this model is \"Stock Change.\" The independent variables include a \"Constant,\" the previously predicted \"Endogenous Param,\" \"Operating Profit,\" and \"Interaction Effect.\" The code is creating a model to understand how changes in the independent variables (like \"Endogenous Param,\" \"Operating Profit,\" and \"Interaction Effect\") relate to changes in the \"Stock Change\" and then a summary of the regression model, including statistical measures like coefficients, p-values, and goodness-of-fit statistics is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Stock Change</td>   <th>  R-squared:         </th> <td>   0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 12 Nov 2023</td> <th>  Prob (F-statistic):</th> <td>1.27e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:24:15</td>     <th>  Log-Likelihood:    </th> <td> -1186.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1696</td>      <th>  AIC:               </th> <td>   2381.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1692</td>      <th>  BIC:               </th> <td>   2403.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Constant</th>           <td>   -0.0176</td> <td>    0.020</td> <td>   -0.896</td> <td> 0.370</td> <td>   -0.056</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Endogenous Param</th>   <td>    0.0011</td> <td>    0.001</td> <td>    1.827</td> <td> 0.068</td> <td>-7.76e-05</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Operating Profit</th>   <td>   -0.1201</td> <td>    0.028</td> <td>   -4.319</td> <td> 0.000</td> <td>   -0.175</td> <td>   -0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Interaction Effect</th> <td>    0.0014</td> <td>    0.000</td> <td>    3.621</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>368.832</td> <th>  Durbin-Watson:     </th> <td>   2.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3433.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.742</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.811</td>  <th>  Cond. No.          </th> <td>    109.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}     &   Stock Change   & \\textbf{  R-squared:         } &     0.015   \\\\\n",
       "\\textbf{Model:}             &       OLS        & \\textbf{  Adj. R-squared:    } &     0.013   \\\\\n",
       "\\textbf{Method:}            &  Least Squares   & \\textbf{  F-statistic:       } &     8.530   \\\\\n",
       "\\textbf{Date:}              & Sun, 12 Nov 2023 & \\textbf{  Prob (F-statistic):} &  1.27e-05   \\\\\n",
       "\\textbf{Time:}              &     21:24:15     & \\textbf{  Log-Likelihood:    } &   -1186.5   \\\\\n",
       "\\textbf{No. Observations:}  &        1696      & \\textbf{  AIC:               } &     2381.   \\\\\n",
       "\\textbf{Df Residuals:}      &        1692      & \\textbf{  BIC:               } &     2403.   \\\\\n",
       "\\textbf{Df Model:}          &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}   &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Constant}           &      -0.0176  &        0.020     &    -0.896  &         0.370        &       -0.056    &        0.021     \\\\\n",
       "\\textbf{Endogenous Param}   &       0.0011  &        0.001     &     1.827  &         0.068        &    -7.76e-05    &        0.002     \\\\\n",
       "\\textbf{Operating Profit}   &      -0.1201  &        0.028     &    -4.319  &         0.000        &       -0.175    &       -0.066     \\\\\n",
       "\\textbf{Interaction Effect} &       0.0014  &        0.000     &     3.621  &         0.000        &        0.001    &        0.002     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 368.832 & \\textbf{  Durbin-Watson:     } &    2.243  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3433.920  \\\\\n",
       "\\textbf{Skew:}          &   0.742 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &   9.811 & \\textbf{  Cond. No.          } &     109.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           Stock Change   R-squared:                       0.015\n",
       "Model:                            OLS   Adj. R-squared:                  0.013\n",
       "Method:                 Least Squares   F-statistic:                     8.530\n",
       "Date:                Sun, 12 Nov 2023   Prob (F-statistic):           1.27e-05\n",
       "Time:                        21:24:15   Log-Likelihood:                -1186.5\n",
       "No. Observations:                1696   AIC:                             2381.\n",
       "Df Residuals:                    1692   BIC:                             2403.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Constant              -0.0176      0.020     -0.896      0.370      -0.056       0.021\n",
       "Endogenous Param       0.0011      0.001      1.827      0.068   -7.76e-05       0.002\n",
       "Operating Profit      -0.1201      0.028     -4.319      0.000      -0.175      -0.066\n",
       "Interaction Effect     0.0014      0.000      3.621      0.000       0.001       0.002\n",
       "==============================================================================\n",
       "Omnibus:                      368.832   Durbin-Watson:                   2.243\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3433.920\n",
       "Skew:                           0.742   Prob(JB):                         0.00\n",
       "Kurtosis:                       9.811   Cond. No.                         109.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2sls = sm.OLS(input_table[\"Stock Change\"], input_table[[\"Constant\",\"Endogenous Param\",\\\n",
    "                                                              \"Operating Profit\",\"Interaction Effect\",\\\n",
    "                                                             ]]).fit()\n",
    "model_2sls.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ordinary Least Squares (OLS) regression results suggest that the model has limited explanatory power (R-squared of 0.015), meaning it explains only about 1.5% of the variability in the \"Stock Change.\" The F-statistic of 8.530 indicates that the model is statistically significant. Examining the coefficients, \"Operating Profit\" and \"Interaction Effect\" appear to be significant predictors of \"Stock Change,\" with coefficients of -0.1201 and 0.0014, respectively. The p-values associated with these variables are less than 0.05, indicating their likely significance. However, the \"Endogenous Param\" variable shows a marginal level of significance (p-value of 0.068). Other diagnostic tests, such as the Omnibus and Jarque-Bera tests, suggest potential deviations from normality in the residuals. Overall, while the model has some explanatory value, its predictive capabilities for \"Stock Change\" are modest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is implementing a Generalized Method of Moments (GMM) model using the gmm class, a subclass of the GMM class from Statsmodels. This model aims to estimate the parameters that best fit the relationship between the dependent variable, \"Stock Change\" (y_vals), and the independent variables, namely \"Inventory Turnover,\" \"Operating Profit,\" and \"Interaction Effect\" (x_vals). Additionally, instrumental variables (\"Current Ratio,\" \"Quick Ratio,\" and \"Debt Asset Ratio\") are used to address potential endogeneity issues. The momcond method defines the moment conditions, representing the discrepancies between the observed and predicted values. The parameters (p0, p1, p2, p3) are optimized to minimize these moment conditions. The initial guess for the parameters is set as beta0. Finally, the GMM model is fitted to the data, and the results, including parameter estimates and statistical information, are summarized using the res.summary() command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000046\n",
      "         Iterations: 8\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000373\n",
      "         Iterations: 7\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000372\n",
      "         Iterations: 5\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000372\n",
      "         Iterations: 5\n",
      "         Function evaluations: 11\n",
      "         Gradient evaluations: 11\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000372\n",
      "         Iterations: 0\n",
      "         Function evaluations: 1\n",
      "         Gradient evaluations: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>gmm Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  Hansen J:          </th> <td>  0.6317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>gmm</td>       <th>  Prob (Hansen J):   </th>  <td> 0.729</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>GMM</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 12 Nov 2023</td> <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:24:15</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1696</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 0</th> <td>   -0.0200</td> <td>    0.021</td> <td>   -0.964</td> <td> 0.335</td> <td>   -0.061</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 1</th> <td>    0.0011</td> <td>    0.001</td> <td>    1.843</td> <td> 0.065</td> <td>-6.89e-05</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 2</th> <td>   -0.1071</td> <td>    0.032</td> <td>   -3.370</td> <td> 0.001</td> <td>   -0.169</td> <td>   -0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 3</th> <td>    0.0011</td> <td>    0.000</td> <td>    2.760</td> <td> 0.006</td> <td>    0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  Hansen J:          } &    0.6317   \\\\\n",
       "\\textbf{Model:}            &       gmm        & \\textbf{  Prob (Hansen J):   } &    0.729    \\\\\n",
       "\\textbf{Method:}           &       GMM        & \\textbf{                     } &             \\\\\n",
       "\\textbf{Date:}             & Sun, 12 Nov 2023 & \\textbf{                     } &             \\\\\n",
       "\\textbf{Time:}             &     21:24:15     & \\textbf{                     } &             \\\\\n",
       "\\textbf{No. Observations:} &        1696      & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "             & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{p 0} &      -0.0200  &        0.021     &    -0.964  &         0.335        &       -0.061    &        0.021     \\\\\n",
       "\\textbf{p 1} &       0.0011  &        0.001     &     1.843  &         0.065        &    -6.89e-05    &        0.002     \\\\\n",
       "\\textbf{p 2} &      -0.1071  &        0.032     &    -3.370  &         0.001        &       -0.169    &       -0.045     \\\\\n",
       "\\textbf{p 3} &       0.0011  &        0.000     &     2.760  &         0.006        &        0.000    &        0.002     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{gmm Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 gmm Results                                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   Hansen J:                       0.6317\n",
       "Model:                            gmm   Prob (Hansen J):                 0.729\n",
       "Method:                           GMM                                         \n",
       "Date:                Sun, 12 Nov 2023                                         \n",
       "Time:                        21:24:15                                         \n",
       "No. Observations:                1696                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "p 0           -0.0200      0.021     -0.964      0.335      -0.061       0.021\n",
       "p 1            0.0011      0.001      1.843      0.065   -6.89e-05       0.002\n",
       "p 2           -0.1071      0.032     -3.370      0.001      -0.169      -0.045\n",
       "p 3            0.0011      0.000      2.760      0.006       0.000       0.002\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vals  = np.array(input_table[\"Stock Change\"])\n",
    "x_vals  = np.array(input_table[[\"Inventory Turnover\",\"Operating Profit\",\"Interaction Effect\"]])\n",
    "iv_vals = np.array(input_table[[\"Current Ratio\",\"Quick Ratio\",\"Debt Asset Ratio\"]])\n",
    "\n",
    "class gmm(GMM):\n",
    "    def momcond(self, params):\n",
    "        p0, p1, p2, p3 = params\n",
    "        endog = self.endog\n",
    "        exog = self.exog\n",
    "        inst = self.instrument   \n",
    "\n",
    "        error0 = endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2]\n",
    "        error1 = (endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2]) * exog[:,1]\n",
    "        error2 = (endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2]) * exog[:,2]\n",
    "        error3 = (endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2]) * inst[:,0] \n",
    "        error4 = (endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2]) * inst[:,1] \n",
    "        error5 = (endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2]) * inst[:,2] \n",
    "\n",
    "        g = np.column_stack((error0, error1, error2, error3, error4, error5))\n",
    "        return g\n",
    "\n",
    "\n",
    "beta0 = np.array([0.1, 0.1, 0.1, 0.1])\n",
    "res = gmm(endog = y_vals, exog = x_vals, instrument = iv_vals, k_moms=6, k_params=4).fit(beta0)\n",
    "\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization of the Generalized Method of Moments (GMM) model was successful, indicating that the model effectively captured the relationship between the dependent variable, denoted as \"y,\" and the specified independent variables. The GMM results, summarized in the table above, provide estimates for the parameters (p0, p1, p2, p3). These coefficients represent the impact of the corresponding variables (\"Constant,\" \"Endogenous Param,\" \"Operating Profit,\" and \"Interaction Effect\") on the dependent variable \"y,\" considering the instrumental variables to address potential endogeneity issues. The p-values associated with each coefficient indicate their statistical significance. Notably, \"Operating Profit\" (p2) has a significant negative effect on \"y,\" while \"Endogenous Param\" (p1) shows a marginal level of significance. The Hansen J statistic and associated probability provide a test for the validity of the instrument choice, suggesting that the instrumental variables are appropriately addressing endogeneity concerns in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Update the GMM model that we discussed in class by incorporating the ùõø term to the instrumental-variable moment expressions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below modifies the Generalized Method of Moments (GMM) model by introducing an additional parameter, denoted as \"delta,\" to address a bias in the instrumental-variable moment conditions, as suggested by an industry expert. The GMM equation is adjusted by adding the \"delta\" term to each moment condition, effectively incorporating the expert's claim into the model. This extra parameter, \"delta,\" is then estimated alongside the other parameters (p0, p1, p2, p3) during the optimization process. The goal is to find the optimal values for all these parameters that best fit the relationship between the dependent variable (\"Stock Change\") and the independent variables (\"Inventory Turnover,\" \"Operating Profit,\" \"Interaction Effect\") while accounting for the suggested bias. The code performs the GMM estimation with the modified moment conditions and presents the results, including parameter estimates and statistical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000031\n",
      "         Iterations: 10\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 15\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000345\n",
      "         Iterations: 9\n",
      "         Function evaluations: 11\n",
      "         Gradient evaluations: 11\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000346\n",
      "         Iterations: 7\n",
      "         Function evaluations: 10\n",
      "         Gradient evaluations: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000346\n",
      "         Iterations: 2\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>gmm_with_delta Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  Hansen J:          </th> <td>  0.5862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>             <td>gmm_with_delta</td>  <th>  Prob (Hansen J):   </th>  <td> 0.444</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>GMM</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 12 Nov 2023</td> <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:24:15</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1696</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 0</th> <td>   -0.0208</td> <td>    0.021</td> <td>   -0.986</td> <td> 0.324</td> <td>   -0.062</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 1</th> <td>    0.0011</td> <td>    0.001</td> <td>    1.839</td> <td> 0.066</td> <td>-7.31e-05</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 2</th> <td>   -0.1062</td> <td>    0.032</td> <td>   -3.316</td> <td> 0.001</td> <td>   -0.169</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 3</th> <td>    0.0011</td> <td>    0.000</td> <td>    2.688</td> <td> 0.007</td> <td>    0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 4</th> <td>   -0.0006</td> <td>    0.003</td> <td>   -0.213</td> <td> 0.831</td> <td>   -0.006</td> <td>    0.005</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  Hansen J:          } &    0.5862   \\\\\n",
       "\\textbf{Model:}            & gmm\\_with\\_delta & \\textbf{  Prob (Hansen J):   } &    0.444    \\\\\n",
       "\\textbf{Method:}           &       GMM        & \\textbf{                     } &             \\\\\n",
       "\\textbf{Date:}             & Sun, 12 Nov 2023 & \\textbf{                     } &             \\\\\n",
       "\\textbf{Time:}             &     21:24:15     & \\textbf{                     } &             \\\\\n",
       "\\textbf{No. Observations:} &        1696      & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "             & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{p 0} &      -0.0208  &        0.021     &    -0.986  &         0.324        &       -0.062    &        0.020     \\\\\n",
       "\\textbf{p 1} &       0.0011  &        0.001     &     1.839  &         0.066        &    -7.31e-05    &        0.002     \\\\\n",
       "\\textbf{p 2} &      -0.1062  &        0.032     &    -3.316  &         0.001        &       -0.169    &       -0.043     \\\\\n",
       "\\textbf{p 3} &       0.0011  &        0.000     &     2.688  &         0.007        &        0.000    &        0.002     \\\\\n",
       "\\textbf{p 4} &      -0.0006  &        0.003     &    -0.213  &         0.831        &       -0.006    &        0.005     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{gmm_with_delta Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            gmm_with_delta Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   Hansen J:                       0.5862\n",
       "Model:                 gmm_with_delta   Prob (Hansen J):                 0.444\n",
       "Method:                           GMM                                         \n",
       "Date:                Sun, 12 Nov 2023                                         \n",
       "Time:                        21:24:15                                         \n",
       "No. Observations:                1696                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "p 0           -0.0208      0.021     -0.986      0.324      -0.062       0.020\n",
       "p 1            0.0011      0.001      1.839      0.066   -7.31e-05       0.002\n",
       "p 2           -0.1062      0.032     -3.316      0.001      -0.169      -0.043\n",
       "p 3            0.0011      0.000      2.688      0.007       0.000       0.002\n",
       "p 4           -0.0006      0.003     -0.213      0.831      -0.006       0.005\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vals  = np.array(input_table[\"Stock Change\"])\n",
    "x_vals  = np.array(input_table[[\"Inventory Turnover\",\"Operating Profit\",\"Interaction Effect\"]])\n",
    "iv_vals = np.array(input_table[[\"Current Ratio\",\"Quick Ratio\",\"Debt Asset Ratio\"]])\n",
    "\n",
    "class gmm(GMM):\n",
    "    def momcond(self, params):\n",
    "        p0, p1, p2, p3, delta = params # The additional parameter (delta) introduced to account for the bias in the instrumental-variable moment conditions\n",
    "        endog = self.endog\n",
    "        exog = self.exog\n",
    "        inst = self.instrument   \n",
    "\n",
    "# The additional term (delta) has been added to the GMM equation. This modification introduces the delta term into the GMM model's moment conditions, addressing the bias in \n",
    "# the  instrumental-variable moment expressions as per the industry expert's suggestion. The delta parameter is then estimated along with the other parameters during the \n",
    "# optimization process.\n",
    "\n",
    "        error0 = endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2] \n",
    "        error1 = (endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2]) * exog[:,1]\n",
    "        error2 = (endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2]) * exog[:,2]\n",
    "        error3 = (endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2]) * inst[:,0] - delta\n",
    "        error4 = (endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2]) * inst[:,1] - delta\n",
    "        error5 = (endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2]) * inst[:,2] - delta\n",
    "\n",
    "        g = np.column_stack((error0, error1, error2, error3, error4, error5))\n",
    "        return g\n",
    "\n",
    "beta0 = np.array([0.1, 0.1, 0.1, 0.1, 0.1])\n",
    "results = gmm_with_delta(endog=y_vals, exog=x_vals, instrument=iv_vals, k_moms=6, k_params=5).fit(beta0_with_delta)\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below performs a hypothesis test to determine whether a specific coefficient, referred to as \"Delta coefficient\" (p4), is statistically significant in a statistical model. The coefficient's significance is assessed by comparing its estimated value (delta_coefficient) to its standard error (delta_std_err). The t_statistic is a measure of how many standard deviations the estimated coefficient is from zero. This statistic is then compared to a critical t-value, which helps decide whether to reject the null hypothesis. The null hypothesis here is that the Delta coefficient is equal to zero, implying it has no effect. If the absolute value of the t_statistic is greater than the critical t-value, the test concludes that the Delta coefficient is statistically significant, and the null hypothesis is rejected; otherwise, it is not considered statistically significant, and the null hypothesis is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta coefficient (p4) is not statistically significant (p-value = 0.8310101210434355), fail to reject the null hypothesis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/base/model.py:1906: FutureWarning: The behavior of wald_test will change after 0.14 to returning scalar test statistic values. To get the future behavior now, set scalar to True. To silence this message while retaining the legacy behavior, set scalar to False.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "coefficients = results.params\n",
    "delta_coefficient = coefficients[4]\n",
    "delta_std_err = results.bse[4] \n",
    "nobs = results.nobs\n",
    "num_coef = len(coefficients)\n",
    "df = nobs - num_coef\n",
    "alpha = 0.05\n",
    "t_statistic = delta_coefficient / delta_std_err\n",
    "critical_t_value = stats.t.ppf(1 - alpha / 2, df)\n",
    "p_value = results.wald_test(r_matrix=np.array([0, 0, 0, 0, 1])).pvalue\n",
    "if abs(t_statistic) > critical_t_value:\n",
    "    print(f\"Delta coefficient (p4) is statistically significant (p-value = {p_value}), reject the null hypothesis.\")\n",
    "else:\n",
    "    print(f\"Delta coefficient (p4) is not statistically significant (p-value = {p_value}), fail to reject the null hypothesis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statement \"Delta coefficient (p4) is not statistically significant (p-value = 0.8310101210434355), fail to reject the null hypothesis\" indicates that the additional term introduced in the model (Delta coefficient) did not have a statistically significant impact on the dependent variable. In hypothesis testing, the null hypothesis typically assumes that there is no effect or relationship, and the p-value represents the probability of observing the data if the null hypothesis is true. In this case, a high p-value (0.831) suggests that we do not have enough evidence to reject the null hypothesis. Therefore, the Delta coefficient may not be a significant factor in explaining the variation in the stock change, as per the statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. By analyzing the GMM summary table and test statistics of coefficients, determine if the industry expert‚Äôs claim is statistically justified.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the analysis of the GMM summary table and the test statistics of coefficients, we can make the following assessment regarding the industry expert's claim about the Œ¥ term:\n",
    "\n",
    "For the GMM model with delta (GMM with delta):\n",
    "\n",
    "The test for the delta coefficient (p4) resulted in a p-value of approximately 0.5903.\n",
    "The null hypothesis was not rejected, indicating that the delta coefficient is not statistically significant in this model.\n",
    "This suggests that, in the context of the GMM model with delta, there is no strong statistical evidence to support the industry expert's claim that the Œ¥ term has a significant effect on the model.\n",
    "\n",
    "The results indicate that, in this particular analysis, the industry expert's claim is not statistically justified.\n",
    "\n",
    "The GMM (Generalized Method of Moments) model includes a new term represented by the coefficient labeled \"p 4\" (delta_coefficient) in the results. This coefficient measures the impact of a specific variable, and in this case, it's labeled as \"p 4.\" The statistical test conducted checks whether this new term is statistically significant.\n",
    "\n",
    "The test results indicate that the \"p 4\" coefficient, often referred to as the delta coefficient, is not statistically significant. This means that the observed value of the delta coefficient is likely due to random chance, and we don't have enough evidence to conclude that it significantly differs from zero. Consequently, the null hypothesis is not rejected. This information is crucial for understanding the importance of the introduced variable in the GMM model, helping to assess whether it significantly contributes to explaining the variation in the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2 (80%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the midterm_parttwo data set from your local file on the computer and store it as 'df'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/pratiksha/Downloads/midterm_parttwo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the info() function which provides a concise summary of our DataFrame, including its column names, data types, and non-null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8081 entries, 0 to 8080\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                Non-Null Count  Dtype \n",
      "---  ------                                --------------  ----- \n",
      " 0   Years of Education after High School  8081 non-null   int64 \n",
      " 1   Requested Credit Amount               8081 non-null   object\n",
      " 2   Number of Dependents                  8081 non-null   object\n",
      " 3   Monthly Income                        8081 non-null   object\n",
      " 4   Monthly Expense                       8081 non-null   object\n",
      " 5   Marital Status                        8081 non-null   object\n",
      " 6   Credit Rating                         8081 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 442.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the below function to display the first few rows of the DataFrame 'df', providing a preview of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years of Education after High School</th>\n",
       "      <th>Requested Credit Amount</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Monthly Income</th>\n",
       "      <th>Monthly Expense</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Credit Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>No dependent</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Married</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>No dependent</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Single</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>No dependent</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Single</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>No dependent</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Married</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>No dependent</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Single</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Years of Education after High School Requested Credit Amount   \n",
       "0                                     1                     Low  \\\n",
       "1                                     2                     Low   \n",
       "2                                     1                     Low   \n",
       "3                                     3                     Low   \n",
       "4                                     3                     Low   \n",
       "\n",
       "  Number of Dependents Monthly Income Monthly Expense Marital Status   \n",
       "0         No dependent       Very low        Very low        Married  \\\n",
       "1         No dependent       Very low        Very low         Single   \n",
       "2         No dependent       Very low        Very low         Single   \n",
       "3         No dependent       Very low        Very low        Married   \n",
       "4         No dependent       Very low        Very low         Single   \n",
       "\n",
       "  Credit Rating  \n",
       "0      Positive  \n",
       "1      Positive  \n",
       "2      Positive  \n",
       "3      Positive  \n",
       "4      Negative  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the describe() function to generate descriptive statistics of the dataframe, such as count, mean, standard deviation, minimum, maximum, and quartile values, for the numerical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years of Education after High School</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8081.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.608588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.571835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Years of Education after High School\n",
       "count                           8081.000000\n",
       "mean                               2.608588\n",
       "std                                1.571835\n",
       "min                                0.000000\n",
       "25%                                1.000000\n",
       "50%                                3.000000\n",
       "75%                                3.000000\n",
       "max                                7.000000"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code iterates through each column in 'df' and for each column, it retrieves the unique values present in that column and prints them out. It helps us understand the different categories or distinct entries within each column of our dataset. This is useful for getting a quick overview of the kinds of information present in each column and aids in understanding the diversity or categories within our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values for Years of Education after High School: [1 2 3 7 4 5 0 6]\n",
      "Unique values for Requested Credit Amount: ['Low' 'Medium' 'High']\n",
      "Unique values for Number of Dependents: ['No dependent' 'Less than 2' 'More than 2']\n",
      "Unique values for Monthly Income: ['Very low' 'Low' 'Moderate' 'High' 'Very High']\n",
      "Unique values for Monthly Expense: ['Very low' 'Low' 'Moderate' 'High' 'Very high']\n",
      "Unique values for Marital Status: ['Married' 'Single' 'Not specified']\n",
      "Unique values for Credit Rating: ['Positive' 'Negative']\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"Unique values for {column}: {unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is transforming categorical values in specific columns of 'df' into numerical representations. For instance, it assigns numerical values to categories like 'Low,' 'Medium,' and 'High' in the 'Requested Credit Amount' column, mapping them to 1, 2, and 3, respectively. This process is repeated for other columns like 'Number of Dependents,' 'Monthly Income,' 'Monthly Expense,' 'Marital Status,' and 'Credit Rating,' where categorical labels are converted into corresponding numerical values. This transformation is  done to prepare the data for machine learning models, as algorithms typically work better with numerical inputs. Now, the DataFrame 'df' contains numerical representations instead of categorical labels in the specified columns, making it more suitable for certain analytical tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Requested Credit Amount'] = df['Requested Credit Amount'].map({'Low': 1, 'Medium': 2, 'High': 3})\n",
    "df['Number of Dependents'] = df['Number of Dependents'].map({'No dependent': 1, 'Less than 2': 2, 'More than 2': 3})\n",
    "df['Monthly Income'] = df['Monthly Income'].map({'Very low':1, 'Low':2, 'Moderate': 3, 'High': 4, 'Very High': 5})\n",
    "df['Monthly Expense'] = df['Monthly Expense'].map({'Very low':1, 'Low':2, 'Moderate': 3, 'High': 4, 'Very high': 5})\n",
    "df['Marital Status'] = df['Marital Status'].map({'Married':1, 'Single':2, 'Not specified': 3})\n",
    "df['Credit Rating'] = df['Credit Rating'].map({'Positive':1, 'Negative':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code now gives the revised values for the columns having the mapped numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values for Years of Education after High School: [1 2 3 7 4 5 0 6]\n",
      "Unique values for Requested Credit Amount: [1 2 3]\n",
      "Unique values for Number of Dependents: [1 2 3]\n",
      "Unique values for Monthly Income: [1 2 3 4 5]\n",
      "Unique values for Monthly Expense: [1 2 3 4 5]\n",
      "Unique values for Marital Status: [1 2 3]\n",
      "Unique values for Credit Rating: [1 0]\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"Unique values for {column}: {unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I printed the first few rows again to have an idea of the dataset after the mapped values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years of Education after High School</th>\n",
       "      <th>Requested Credit Amount</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Monthly Income</th>\n",
       "      <th>Monthly Expense</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Credit Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Years of Education after High School  Requested Credit Amount   \n",
       "0                                     1                        1  \\\n",
       "1                                     2                        1   \n",
       "2                                     1                        1   \n",
       "3                                     3                        1   \n",
       "4                                     3                        1   \n",
       "\n",
       "   Number of Dependents  Monthly Income  Monthly Expense  Marital Status   \n",
       "0                     1               1                1               1  \\\n",
       "1                     1               1                1               2   \n",
       "2                     1               1                1               2   \n",
       "3                     1               1                1               1   \n",
       "4                     1               1                1               2   \n",
       "\n",
       "   Credit Rating  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              0  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Divide the dataset equally into two as training (50%) and test (50%) sets. Use the training set to fit a logistic regression model, where the credit rating is the dependent variable. Apply the model to the test set, and report the confusion matrix, recall, precision, and F1 score values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is organizing data for a machine learning model. It separates features (X) and the target variable ('Credit Rating'). The dataset is then split into training and test sets using the train_test_split function, allocating 50% for training and 50% for testing. The training set is used to teach the model, and the test set evaluates its performance on new, unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('Credit Rating', axis=1)\n",
    "y = df['Credit Rating']\n",
    "\n",
    "# Split the dataset into training and test sets (50% each)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code, a logistic regression model is created using the LogisticRegression function. Logistic regression is a type of algorithm used for binary classification tasks, like predicting whether an outcome is positive or negative. The model is then trained on the training set (X_train and y_train) using the fit method. This training process involves adjusting the model's parameters based on the input features (X_train) to make accurate predictions of the target variable (y_train). After this step, the logistic regression model is ready to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a logistic regression model\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training set\n",
    "logreg_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code generates predictions for the test set using the logistic regression model that was previously trained on the training set. The predict function takes the features of the test set (X_test) as input and produces predicted values for the target variable. In this context, it predicts the 'Credit Rating' based on the features in the test set. These predictions can be compared with the actual 'Credit Rating' values in the test set (y_test) to evaluate how well the model performs on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test set\n",
    "y_pred = logreg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below assesses the performance of the logistic regression model on the test set. It calculates a confusion matrix, a table that summarizes the model's predictions versus the actual values in the test set. The confusion matrix helps analyze the model's accuracy, precision, recall, and F1 score. The classification_report function generates a comprehensive report with metrics such as precision, recall, and F1 score for each class. The printed results include the confusion matrix and the classification report, offering insights into the model's ability to correctly predict positive and negative outcomes, providing a holistic view of its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[   0  577]\n",
      " [   0 3464]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       577\n",
      "           1       0.86      1.00      0.92      3464\n",
      "\n",
      "    accuracy                           0.86      4041\n",
      "   macro avg       0.43      0.50      0.46      4041\n",
      "weighted avg       0.73      0.86      0.79      4041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Before Threshold Adjustment\n",
    "\n",
    "### Metrics:\n",
    "- **Recall (Sensitivity or True Positive Rate):** 1.00\n",
    "- **Precision:** 0.86\n",
    "- **F1 Score:** 0.92\n",
    "\n",
    "### Confusion Matrix:\n",
    "[[   0  577]\n",
    " [   0 3464]]\n",
    "\n",
    "### Interpretation:\n",
    "1. **Recall:** The model correctly identified all positive instances (credit fully repaid) in the test set.\n",
    "2. **Precision:** 86% of instances predicted as positive were actually positive.\n",
    "3. **F1 Score:** A balanced performance between precision and recall, with a score of 0.92.\n",
    "4. **Confusion Matrix:** All instances were predicted as negative, indicating a potential issue with the model's threshold for predicting positive instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix and classification report provide insights into the logistic regression model's performance on the test set. In the confusion matrix, the first row represents instances labeled as class 0 (not approved), and the second row represents class 1 (approved). The model correctly identified all instances of class 1 (approved) but failed to identify any instances of class 0 (not approved), resulting in a precision of 0% for class 0. The recall for class 1 is 100%, indicating that the model successfully captured all positive instances. The overall accuracy is 86%, reflecting the proportion of correctly predicted instances. The model consistently predicts a positive credit score for every instance. The perfect recall of 1 indicates that it doesn't miss any true positive predictions. The high precision (86%) implies that when the model predicts a positive credit score, it is correct 86% of the time. However, the drawback is that 15% of the time, it falsely predicts a positive credit score. Overall, this model is suboptimal, as it indiscriminately labels every customer as having a positive credit score, lacking the necessary discrimination to make meaningful predictions.However, the precision and recall imbalance suggests potential issues, and the F1-score provides a harmonic mean of precision and recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Suppose that the bank decided to make the credit approval process more challenging such that only 15% of the applications would be granted. Calculate the threshold value for the prediction probability, so only 15% of the test set would get their applications approved. Then, update your confusion matrix, recall, precision, and F1 scores.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code deals with predicting probabilities using a logistic regression model on the test set. Instead of just predicting binary outcomes, it computes the probabilities of a positive outcome for each instance. The code then calculates a threshold value that would result in a 15% approval rate. This threshold is applied to the predicted probabilities, classifying instances with probabilities above the threshold as approved (1) and below as not approved (0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities on the test set\n",
    "y_probs = logreg_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the threshold for a 15% approval rate\n",
    "desired_approval_rate = 0.15\n",
    "threshold = sorted(y_probs)[int((1 - desired_approval_rate) * len(y_probs))]\n",
    "\n",
    "# Update predictions based on the new threshold\n",
    "y_pred_updated = (y_probs >= threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below evaluates the logistic regression model with the updated threshold on the test set. The confusion matrix is calculated to compare the model's predictions against the actual values, considering the adjusted decision boundary. The classification report is then generated, providing metrics such as precision, recall, and F1 score for each class. These metrics offer insights into the model's performance when the decision threshold is customized to achieve a specific approval rate, allowing for a more tailored evaluation of the model's effectiveness under the desired criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model with the updated threshold\n",
    "conf_matrix_updated = confusion_matrix(y_test, y_pred_updated)\n",
    "classification_rep_updated = classification_report(y_test, y_pred_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The printed results showcase the performance of the logistic regression model with the updated threshold on the test set. The confusion matrix provides a summary of the model's predictions compared to the actual outcomes, considering the adjusted decision boundary for a 15% approval rate. The classification report offers detailed metrics such as precision, recall, and F1 score for each class, giving a comprehensive view of how well the model performs under the specified criteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Updated):\n",
      "[[ 499   78]\n",
      " [2922  542]]\n",
      "\n",
      "Classification Report (Updated):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.86      0.25       577\n",
      "           1       0.87      0.16      0.27      3464\n",
      "\n",
      "    accuracy                           0.26      4041\n",
      "   macro avg       0.51      0.51      0.26      4041\n",
      "weighted avg       0.77      0.26      0.26      4041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(\"Confusion Matrix (Updated):\")\n",
    "print(conf_matrix_updated)\n",
    "print(\"\\nClassification Report (Updated):\")\n",
    "print(classification_rep_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results After Threshold Adjustment\n",
    "\n",
    "### Metrics:\n",
    "- **Confusion Matrix with New Threshold:**\n",
    "[[ 499   78]\n",
    " [2922  542]]\n",
    "- **Recall with New Threshold:** 0.15\n",
    "- **Precision with New Threshold:** 0.87\n",
    "- **F1 Score with New Threshold:** 0.26\n",
    "\n",
    "### Updated Interpretation:\n",
    "1. **Confusion Matrix with New Threshold:** \n",
    "   - True Positives (TP): 528\n",
    "   - True Negatives (TN): 495\n",
    "   - False Positives (FP): 82\n",
    "   - False Negatives (FN): 2936\n",
    "\n",
    "2. **Recall with New Threshold:** \n",
    "   - The model correctly identified 15% of positive instances (credit fully repaid) in the test set.\n",
    "\n",
    "3. **Precision with New Threshold:** \n",
    "   - 87% of instances predicted as positive were actually positive.\n",
    "\n",
    "4. **F1 Score with New Threshold:** \n",
    "   - The F1 score has dropped significantly to 0.26, indicating a trade-off between precision and recall. This could be a result of the more challenging threshold, making the model conservative in predicting positive instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The updated confusion matrix and classification report reflect the model's performance with a modified threshold aiming for a 15% approval rate. In the confusion matrix, the model now approves a small portion of applications (499) that were previously rejected (class 0), reducing false negatives but increasing false positives. The precision for class 0 has improved to 15%, indicating a modest ability to correctly identify rejected instances. However, the recall for class 0 is high (86%), demonstrating that a substantial number of actual rejected instances are still being missed. The overall accuracy has dropped to 26%, emphasizing the challenges of balancing precision and recall. The decision to limit the model to a 15% approval rate has markedly affected its performance. True negatives increased from 0 to 499, and false positives dropped from 577 to 78, indicating a more conservative approach. However, this adjustment led to a notable increase in false negatives and a decline in true positives, reflecting the impact of predicting positives in only 15% of the samples. Given that around 86% of applications genuinely have positive credit scores, this restriction significantly influences the model's accuracy in identifying positive cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below generates a precision-recall curve to visualize how changing the threshold impacts the precision and recall of the logistic regression model. The x-axis represents different threshold values, and the y-axis shows corresponding precision and recall values. The curve illustrates the trade-off between precision (the ability to avoid false positives) and recall (the ability to identify all relevant instances). By examining this curve, one can assess how adjusting the decision threshold influences the balance between precision and recall, aiding in the fine-tuning of the model based on specific criteria or priorities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the precision-recall curve to visualize the effect of changing the threshold\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "\n",
    "plt.plot(thresholds, precision[:-1], label='Precision')\n",
    "plt.plot(thresholds, recall[:-1], label='Recall')\n",
    "plt.xlabel('Threshold')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________________________________________________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
